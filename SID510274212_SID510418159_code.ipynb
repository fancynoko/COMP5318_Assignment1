{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIcuB1qpXXzV"
   },
   "source": [
    "# COMP5318 - Machine Learning and Data Mining: Assignment 1\n",
    "<div style=\"text-align: right\"> Due: Friday Week 7 - Fri 8 April 2022 11:59PM </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-u7p4JTIXXza",
    "nbpresent": {
     "id": "375753da-1c6c-4b02-986a-6e3b185a5869"
    }
   },
   "source": [
    "# 1. Summary\n",
    "The goal of this assignment is to build a classifier to classify some grayscale images of the size 28x28 into a set of categories. The dimension of the original data is large, so you need to be smart on which method you gonna use and perhaps perform a pre-processing step to reduce the amount of computation. Part of your marks will be a function of the performance of your classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlWbZY7JXXzc"
   },
   "source": [
    "# 2. Dataset description\n",
    "The dataset can be downloaded from Canvas. The dataset consists of a training set of 30,000 examples and a test set of 5,000 examples. They belong to 10 different categories. The validation set is not provided, but you can randomly pick a subset of the training set for validation. The features of the 5,000 test examples are given, you will analyse the performance of your proposed method by uploading the predicted labels of test examples onto [Kaggle Leaderboard](https://www.kaggle.com/t/a781604ffe46a42f903dd4be1b9daf16). You can find the instruction of using the leaderboard in Part 5.2. The leaderboard will compute the accuracy of your model, and team ranking will be shown based on the performance. Please note that we provide only PART of the original Fashion-MNIST, you must use the GIVEN `train.csv` (not the original dataset from the official website) for training; or it will be considered as cheating. <br />\n",
    "Here are examples illustrating samples of the dataset (each class takes one row):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRTiLolPXXzo"
   },
   "source": [
    "<img src=\"Dataset_image.jpg\" alt=\"DataSet\" title=\"DataSet\" width=\"450\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBPRrkMpXXzo"
   },
   "source": [
    "There are 10 classes in total:\n",
    "\n",
    "    - 0 T-shirt/Top\n",
    "    - 1 Trouser\n",
    "    - 2 Pullover\n",
    "    - 3 Dress\n",
    "    - 4 Coat\n",
    "    - 5 Sandal\n",
    "    - 6 Shirt\n",
    "    - 7 Sneaker\n",
    "    - 8 Bag\n",
    "    - 9 Ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MSUFRO4XXzp"
   },
   "source": [
    "# 3. Load the data and make output prediciton\n",
    "An Input folder including only 2 files (which can be downloaded from Canvas):\n",
    "\n",
    "    1. train.csv (30000 image samples for training including features and label) \n",
    "    2. test_input.csv (5000 images for prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwI46pc3XXzq"
   },
   "source": [
    "## 3.1 Load the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssDOH7_NXXzr"
   },
   "source": [
    "To read the *csv* file and load the data into a dataframe using pandas. \n",
    "\n",
    "The **training data files are in the ./Input/train** and **testing data file are in ./Input/test**. <br /> Use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Qzyym0PXXzt",
    "outputId": "af493312-4da6-451b-efd7-0353f56995d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "print(os.listdir(\"./Input/train\"))\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SIz7li7zXXzv"
   },
   "outputs": [],
   "source": [
    "# train.csv including feature and label using for training model.\n",
    "data_train_df = pd.read_csv('./Input/train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "p3IKpXj1XXzw",
    "outputId": "6b08fbe0-2f73-44b8-904e-acd65535b4e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>...</th>\n",
       "      <th>v781</th>\n",
       "      <th>v782</th>\n",
       "      <th>v783</th>\n",
       "      <th>v784</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  v1  v2  v3  v4  ...  v781  v782  v783  v784  label\n",
       "0   0   0   0   0   0  ...     0     0     0     0      2\n",
       "1   1   0   0   0   0  ...     0     0     0     0      1\n",
       "2   2   0   0   0   0  ...     0     0     0     0      1\n",
       "3   3   0   0   0   1  ...     0     0     0     0      4\n",
       "4   4   0   0   0   0  ...     0     0     0     0      8\n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-CkkeqQXXzx"
   },
   "source": [
    "Then data would be a dataframe with 30000 samples including 784 features (from v1 to v784) and its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QZsQNQLUXXzx"
   },
   "outputs": [],
   "source": [
    "# Selecting input feature\n",
    "data_train_feature = data_train_df.loc[:, \"v1\":\"v784\"].to_numpy()\n",
    "\n",
    "# Selecting output lable \n",
    "data_train_label = data_train_df.label.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fDpn0DwXXzy"
   },
   "source": [
    "Showing a sample data. The first example belongs to class 2: Pullover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EcnqIBxnXXzz",
    "outputId": "db703ea6-d2f7-4f43-dc5e-8265db1214a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   1   0   0 131 184 199 229 234 217 212 204 208 226 227\n",
      "  203 185 173  44   0   4   0   0   0   0]\n",
      " [  0   0   0   0   2   0   0 214 224 116  78 149 141 148 131 121 141 141\n",
      "  169 212 251 136   0  10   0   0   0   0]\n",
      " [  0   0   1   0   5   0  43 220 217 213 104  13   6  49  36  11  37 121\n",
      "  179 208 227 155   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0 155 233 217 226 255 252 133  64 109 127 175 240\n",
      "  232 209 224 204   0   0   3   0   0   0]\n",
      " [  0   0   0   3   0   0 212 227 223 223 217 230 241 237 210 252 229 222\n",
      "  213 218 221 216   0   0   7   0   0   0]\n",
      " [  0   0   3   0  13 193 223 215 218 215 224 225 219 213 209 212 217 225\n",
      "  225 224 217 223 198   0   0   2   0   0]\n",
      " [  0   0   0   0 197 227 211 216 215 251 236 212 250 221 213 213 207 209\n",
      "  208 212 214 210 232 169   0   0   0   0]\n",
      " [  0   0   0  13 214 206 216 214 246 116  14  29   0 212 215 211 214 209\n",
      "  211 210 209 212 203 207   4   0   0   0]\n",
      " [  0   0   0  62 223 208 222 229 195   0 103   0   0 137 240 200 219 214\n",
      "  211 207 212 216 204 221  70   0   0   0]\n",
      " [  0   0   0 104 223 203 224 236 191  66  19  59  35  96 227 203 207 223\n",
      "  221 211 204 215 203 224 131   0   0   0]\n",
      " [  0   0   0 169 220 204 221 222 229  34   0  54   0 230 199 204 208 210\n",
      "  226 223 209 217 208 216 193   0   0   0]\n",
      " [  0   0   0 206 216 205 220 223 164 221 156 149 239 217 140 244 223 139\n",
      "  152 230 216 219 209 211 217   0   0   0]\n",
      " [  0   0   0 222 213 205 222 219 150 152 201 171 162 121 120 156 151 130\n",
      "  162 225 214 221 211 211 225   0   0   0]\n",
      " [  0   0   0 233 209 207 231 230 173 164 176 155 163 174 141 150 147 153\n",
      "  157 195 221 227 216 209 238   0   0   0]\n",
      " [  0   0  11 245 208 204 230 231 137 147 144 133 125 126 126 134 129 131\n",
      "  138 193 208 222 218 207 215  39   0   0]\n",
      " [  0   0  31 246 206 199 222 251 139  73  85  77  92 111 130 150 176 187\n",
      "  200 218 206 222 219 207 248  55   0   0]\n",
      " [  0   0  56 248 203 203 225 248 210 154 210 234 236 235 235 230 224 217\n",
      "  212 213 207 222 220 208 245  61   0   0]\n",
      " [  0   0  65 246 205 200 229 235 204 229 226 208 204 204 205 204 207 205\n",
      "  205 211 203 219 223 209 245  72   0   0]\n",
      " [  0   0  85 244 203 196 239 233 202 206 208 210 210 211 213 208 206 212\n",
      "  209 210 204 218 227 210 243  79   0   0]\n",
      " [  0   0 119 241 202 194 242 225 206 213 213 212 212 211 212 209 205 213\n",
      "  212 210 204 216 229 210 240 102   0   0]\n",
      " [  0   0 145 230 200 201 240 221 208 214 214 212 212 213 213 210 204 208\n",
      "  212 212 204 217 229 210 234 124   0   0]\n",
      " [  0   0 171 223 211 200 239 224 206 215 216 214 213 213 213 211 207 207\n",
      "  211 212 207 220 224 210 235 164   0   0]\n",
      " [  0   0 133 237 210 204 235 226 206 214 214 213 212 214 214 213 210 208\n",
      "  211 212 206 219 226 210 244 103   0   0]\n",
      " [  0   0  32 217 204 207 239 229 207 213 213 211 209 213 214 213 210 212\n",
      "  212 211 200 220 226 214 221  40   0   0]\n",
      " [  0   0  33 219 209 211 204 208 219 210 214 212 211 212 212 212 209 212\n",
      "  216 214 209 211 236 212 231  55   0   0]\n",
      " [  0   0  21 199 215 228 149 168 224 210 211 212 214 214 213 214 212 211\n",
      "  207 205 212  89 233 222 197  21   0   0]\n",
      " [  0   0   0   0  12  21   0 217 239 217 224 220 218 215 217 222 222 226\n",
      "  236 219 255  51   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  48 172 181 198 206 209 210 208 202 194 186\n",
      "  175 143 106   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data_train_feature_pre = data_train_feature.reshape((data_train_feature.shape[0], 28, 28))\n",
    "print(data_train_feature_pre[0])\n",
    "plt.imshow(data_train_feature_pre[0], cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"class \" + str(data_train_label[0]) + \": Pullover\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6GspGVoXXz3",
    "nbpresent": {
     "id": "1e4a01db-cd92-48f8-bdaa-21c39456cfcb"
    }
   },
   "source": [
    "# 4. Task description\n",
    "\n",
    "Your task is to determine / build a classifier for the given data set to classify images into categories and write a report. The score allocation is as follows:\n",
    "\n",
    "    1. Code: max 65 points\n",
    "    2. Report: max 35 points\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NRCScxRXXz3"
   },
   "source": [
    "## 4.1 Code\n",
    "### The code must clearly show :\n",
    "    1. Pre-process data\n",
    "    2. Details of your implementation for each algorithm\n",
    "    3. Fine-tune hyper-parameters for each algorithm and running time\n",
    "    4. The comparison result between 4 different algorithms including 3 single methods and one ensemble method\n",
    "    5. Hardware and software specifications of the computer that you used for performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_Yz_KvTXXz4"
   },
   "source": [
    "### 4.1.1 Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6xnrDPvAXXz5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Normalize the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_train_feature, data_train_label , random_state=42\n",
    ")\n",
    "\n",
    "s = MinMaxScaler()\n",
    "s.fit(X_train)\n",
    "Norm_data_train = s.transform(X_train)\n",
    "Norm_data_test = s.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "PXFUx8ZJMu_0",
    "outputId": "e78a1017-4166-4e5c-a419-455eb6b5179e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Using PCA to check the minimum numnber of features that should be used.  \n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np \n",
    "pca = PCA()\n",
    "pca.fit(Norm_data_train)\n",
    "axissum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "dimensions = np.argmax(axissum >= 0.95) + 1\n",
    "print(dimensions) # 186 features are needed to preserve 95% of the variance\n",
    "\n",
    "# #Visualize the dimension to check the best number of dimensions to use \n",
    "# Plot explained variance vs number of dimensions\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(axissum, linewidth=3)\n",
    "plt.axis([0, 400, 0, 1])\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.plot([dimensions, dimensions], [0, 0.95], \"k:\")\n",
    "plt.plot([0, dimensions], [0.95, 0.95], \"k:\")\n",
    "plt.plot(dimensions, 0.95, \"ko\")\n",
    "plt.annotate(\"Elbow\", xy=(65, 0.85), xytext=(70, 0.7),\n",
    "             arrowprops=dict(arrowstyle=\"->\"), fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jz0g1BA1N4m8",
    "outputId": "7a6acde2-5318-4ed9-db05-4abcda13f7a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 186)\n",
      "(7500, 186)\n"
     ]
    }
   ],
   "source": [
    "# Fit PCA model to normalize dataset \n",
    "pca_model = PCA(n_components=186)\n",
    "X_train_reduce = pca_model.fit_transform(Norm_data_train)\n",
    "X_test_reduce = pca_model.transform(Norm_data_test)\n",
    "print(X_train_reduce.shape)\n",
    "print(X_test_reduce.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z4dyOLOXXz5"
   },
   "source": [
    "### 4.1.2 Classification algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FezOflJbXXz6"
   },
   "source": [
    "\n",
    "Apply four classifier to the pre-processed dataset:\n",
    "\n",
    "    1. Nearest Neighbor\n",
    "    2. Logistic Regression\n",
    "    3. Decision Tree\n",
    "    4. SVM\n",
    "\n",
    "and one ensemble method:\n",
    "    \n",
    "    1. Random forest\n",
    "    \n",
    "For binary classifiers, we can use those classifiers for the data which has more than 2 labels using the one-vs-rest method. The implementation can use sklearn, or can be implemented from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Gnc4uflIWTY6"
   },
   "outputs": [],
   "source": [
    "# Import the accuracy score module \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3mmYOz2XXz6",
    "outputId": "907cd5cf-189a-442f-dd30-070440235a23",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier accuracy on the test set: 0.85\n"
     ]
    }
   ],
   "source": [
    "#Neareast Neighbor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "nn = KNeighborsClassifier()\n",
    "nn.fit(X_train_reduce, y_train)\n",
    "output_prediction = nn.predict(X_test_reduce)\n",
    "print(\"KNN Classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, output_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLM18AKoXXz7",
    "outputId": "5889044d-c0d3-4f39-8d35-c73d1c3f529b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier accuracy on the test set: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## One versus rest with multiclass set to 'ovr'\n",
    "log_regression = LogisticRegression(multi_class='ovr')\n",
    "log_regression.fit(X_train_reduce, y_train)\n",
    "l_predict = log_regression.predict(X_test_reduce)\n",
    "print(\"Logistic Regression Classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, l_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWs-RXWWXXz8",
    "outputId": "500631cd-c213-4801-c61b-189cfa9679dc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decsion tree classifier accuracy on the test set: 0.74\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tr = DecisionTreeClassifier()\n",
    "tr.fit(X_train_reduce, y_train)\n",
    "t_predict = tr.predict(X_test_reduce)\n",
    "print(\"Decsion tree classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, t_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5gp9Lp3XXz8",
    "outputId": "633c91ca-5e31-4a1e-bad3-ff6a8cedbdcc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM - accuracy on test set: 0.882\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "SVC = SVC(decision_function_shape='ovr')\n",
    "SVC.fit(X_train_reduce, y_train)\n",
    "svc_predict = SVC.predict(X_test_reduce)\n",
    "print(\"Linear SVM - accuracy on test set: {:.3f}\".format(accuracy_score(y_test, svc_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhSXIzKGXXz9"
   },
   "source": [
    "#### Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9SekY3hCF8x",
    "outputId": "acd81f73-c551-4722-c475-93a8086c323e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest ensembles of decsion tree:0.85\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_tree = RandomForestClassifier()\n",
    "rf_tree.fit(X_train_reduce, y_train)\n",
    "rf_predict = rf_tree.predict(X_test_reduce)\n",
    "print(\"Random Forest ensembles of decsion tree:{:.2f}\".format(accuracy_score(y_test, rf_predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFNzX7OoXXz9"
   },
   "source": [
    "### 4.1.3 Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDwNKXJeXXz-"
   },
   "source": [
    "For each classifiers we would like to find the best parameters using grid search with k-fold (k>=5) cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ufBoTcqcmWP1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJ_3HXGkXXz-",
    "outputId": "7f94a38c-bbce-4b66-b95c-2607dcbd00fd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Test set score: 0.85\n",
      "KNN Best parameters: {'n_neighbors': 5, 'p': 1}\n",
      "KNN Best cross-validation score: 0.85\n",
      "KNN Best estimator:\n",
      "KNeighborsClassifier(p=1)\n"
     ]
    }
   ],
   "source": [
    "# Tuning for KNeighbor Classifier\n",
    "KNN_para = {'n_neighbors': [1,3,5,11,15], 'p':[1,2]}\n",
    "\n",
    "\n",
    "\n",
    "grid_search_knn = GridSearchCV(nn, KNN_para, cv=5)\n",
    "grid_search_knn.fit(Norm_data_train, y_train)\n",
    "\n",
    "print(\"KNN Test set score: {:.2f}\".format(grid_search_knn.score(Norm_data_test, y_test)))\n",
    "print(\"KNN Best parameters: {}\".format(grid_search_knn.best_params_))\n",
    "print(\"KNN Best cross-validation score: {:.2f}\".format(grid_search_knn.best_score_))\n",
    "print(\"KNN Best estimator:\\n{}\".format(grid_search_knn.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lP7j0J2LXXz_",
    "outputId": "7d17df69-b6ca-43ae-977c-35b4017620a0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression test set score: 0.84\n",
      "Logistic regression best parameters: {'max_iter': 2000}\n",
      "Logistic regression best cross-validation score: 0.84\n",
      "Logistic regression best estimator:\n",
      "LogisticRegression(max_iter=2000)\n"
     ]
    }
   ],
   "source": [
    "# Tuning for Logistic Regression classifier\n",
    "lr_para = {\n",
    "           'max_iter':[2000, 3000, 6000]}\n",
    "grid_search_lr = GridSearchCV(log_regression, lr_para, cv=5, return_train_score=10)\n",
    "grid_search_lr.fit(Norm_data_train, y_train)\n",
    "print(\"Logistic regression test set score: {:.2f}\".format(grid_search_lr.score(Norm_data_test, y_test)))\n",
    "print(\"Logistic regression best parameters: {}\".format(grid_search_lr.best_params_))\n",
    "print(\"Logistic regression best cross-validation score: {:.2f}\".format(grid_search_lr.best_score_))\n",
    "print(\"Logistic regression best estimator:\\n{}\".format(grid_search_lr.best_estimator_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-ftzQPRXX0A",
    "outputId": "41b248e9-a3cb-4cf3-be36-ba43ad875759",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree test set score: 0.78\n",
      "Decision Tree best parameters: {'min_samples_split': 30}\n",
      "Decision Tree best cross-validation score: 0.78\n",
      "Decision Tree best estimator:\n",
      "DecisionTreeClassifier(criterion='entropy', min_samples_split=30,\n",
      "                       random_state=42, splitter='random')\n"
     ]
    }
   ],
   "source": [
    "# Tuning for Decision Tree\n",
    "tree_para = {\"min_samples_split\": [10,20,30,40]}\n",
    "grid_search_dt = GridSearchCV(tr, tree_para, cv=5, return_train_score=True)\n",
    "grid_search_dt.fit(Norm_data_train, y_train)\n",
    "print(\"Decision Tree test set score: {:.2f}\".format(grid_search_dt.score(Norm_data_test, y_test)))\n",
    "print(\"Decision Tree best parameters: {}\".format(grid_search_dt.best_params_))\n",
    "print(\"Decision Tree best cross-validation score: {:.2f}\".format(grid_search_dt.best_score_))\n",
    "print(\"Decision Tree best estimator:\\n{}\".format(grid_search_dt.best_estimator_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNagX1t_XX0A",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Tuning for Ensemble method of RandomForest classifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_para = {\"n_estimators\":[50, 100, 150, 200,400], \"max_depth\":[30,50,70], \"criterion\":[\"gini\",\"entropy\"], \"min_samples_split\":[1,2,3,4,5,10,20,30,40],\n",
    "               \"n_jobs\": [-1]}\n",
    "\n",
    "grid_search_randf = GridSearchCV(RandomForestClassifier(), forest_para, cv=5, return_train_score=True)\n",
    "grid_search_randf.fit(X_train_reduce, y_train)\n",
    "\n",
    "print(\"Random Forest test set score: {:.2f}\".format(grid_search_randf.score(X_test_reduce, y_test)))\n",
    "print(\"Random Forest best parameters: {}\".format(grid_search_randf.best_params_))\n",
    "print(\"Random Forest best cross-validation score: {:.2f}\".format(grid_search_randf.best_score_))\n",
    "print(\"Random Forest best estimator:\\n{}\".format(grid_search_randf.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYo8oHC6Uo_U"
   },
   "outputs": [],
   "source": [
    "# Tuning for SVM \n",
    "# Runnable but time intensive. \n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Use GridSearcCV on the training set\n",
    "from sklearn.svm import SVC\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=10,\n",
    "                          return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train_reduce, y_train)\n",
    "\n",
    "# Accuracy on test set of the model with selected best parameters:\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test_reduce, y_test)))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDZj3xs6XX0A"
   },
   "source": [
    "### 4.1.4 Classifier comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smuWn72rXX0A"
   },
   "source": [
    "After finding the best parameter for each algorithm, we would like to make comparisons between all classifiers using their own best hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WO07J7CKXX0B",
    "outputId": "3c718e28-d860-44fe-9914-de9129f99604",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier accuracy on the test set: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Optimized Classifier of KNN with the best hyper_parameters\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "opt_nn = KNeighborsClassifier(n_neighbors=5, p=1, n_jobs=-1)\n",
    "opt_nn.fit(Norm_data_train, y_train)\n",
    "opt_output_prediction = opt_nn.predict(Norm_data_test)\n",
    "print(\"KNN Classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, opt_output_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-G-Kl8bR0IP",
    "outputId": "22649ec1-07c2-4326-9419-b104f68d2da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier accuracy on the test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Optimized Classifier of logistic regression with best hyperparameter \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "opt_log = LogisticRegression(max_iter=2000)\n",
    "opt_log.fit(Norm_data_train, y_train)\n",
    "opt_log_predict = opt_log.predict(Norm_data_test)\n",
    "print(\"Logistic Regression Classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, opt_log_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNjFje4OR2aZ",
    "outputId": "5d6d9e7c-781f-44ac-8bcb-a3b4fbcf7e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier accuracy on the test set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Optimized Classifier of Decision Tree with the best hyper_parameter \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "opt_tree = DecisionTreeClassifier(criterion='entropy', min_samples_split=30,\n",
    "                       random_state=42, splitter='random')\n",
    "opt_tree.fit(Norm_data_train, y_train)\n",
    "opt_tree_predict = opt_tree.predict(Norm_data_test)\n",
    "print(\"Decision Tree Classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, opt_tree_predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lz9dVVRkR2C4",
    "outputId": "d805049e-a72d-4c3b-b812-730d4b5f8a02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier accuracy on the test set: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Optimized Classifier of random forest with the best hyper_parameter \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "opt_rand_forest = RandomForestClassifier(max_depth=70,\n",
    " max_features='auto',\n",
    " min_samples_leaf=4,\n",
    " min_samples_split=10,\n",
    " n_estimators=400)\n",
    "opt_rand_forest.fit(Norm_data_train, y_train)\n",
    "opt_rand_forest_predict = opt_rand_forest.predict(Norm_data_test)\n",
    "print(\"Random forest classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, opt_rand_forest_predict)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNdUwmgl7nW0",
    "outputId": "767e3e1c-6b19-4ba7-f998-ea360156b44c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - accuracy on test set: 0.878\n"
     ]
    }
   ],
   "source": [
    "# Optimized parameter with SVC\n",
    "# Since the tuning is time intensive, we only set decision function shape to be \n",
    "# 'ovr' for binary classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "opt_svc = SVC(decision_function_shape='ovr')\n",
    "opt_svc.fit(Norm_data_train, y_train)\n",
    "svc_predict = opt_svc.predict(Norm_data_test)\n",
    "print(\"SVM - accuracy on test set: {:.3f}\".format(accuracy_score(y_test, svc_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgwHc_e-Qy4M"
   },
   "source": [
    "# 5.Output Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td0bPQ0roOnN"
   },
   "source": [
    "Load test data and output the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lz29rzZ3ohHk"
   },
   "outputs": [],
   "source": [
    "# test_input.csv includes 5000 samples used for label prediction. Test samples do not have labels.\n",
    "data_test_df = pd.read_csv('./Input/test/test_input.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "XrVnkmDrojJe",
    "outputId": "7a4a148c-766e-47fc-d67b-cf14c92dc38a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>...</th>\n",
       "      <th>v780</th>\n",
       "      <th>v781</th>\n",
       "      <th>v782</th>\n",
       "      <th>v783</th>\n",
       "      <th>v784</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    v1  v2  v3  v4  v5  ...  v780  v781  v782  v783  v784\n",
       "id                      ...                              \n",
       "0    0   0   0   0   0  ...     0     0     0     0     0\n",
       "1    0   0   0   0   0  ...     0     0     0     0     0\n",
       "2    0   0   0   0   0  ...     0     0     0     0     0\n",
       "3    0   0   0   0   0  ...     0     0     0     0     0\n",
       "4    0   0   0   0   0  ...     0     0     0     0     0\n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvFUAwWZo6Bc"
   },
   "source": [
    "After making a prediction on test data, all predicted lables will be saved in “test_output.csv”. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrLlfrtVRgbY"
   },
   "source": [
    "Here are the output predictions using the test input file. The output csv files are uploaded to kaggle for a score evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lkKBuV98t_-k"
   },
   "outputs": [],
   "source": [
    "# Use the highest parameter tuning score in the models to predict the label, test file as input. \n",
    "# Extract the features from test file \n",
    "data_test_feature = data_test_df.loc[:, \"v1\": \"v784\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUPQrsuiSdPb"
   },
   "source": [
    "Output CSV file for Support Vector Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "DIETWF619C6P"
   },
   "outputs": [],
   "source": [
    "ouput_svc = opt_svc.predict(data_test_feature)\n",
    "output_svc_df = pd.DataFrame(ouput_svc, columns = ['label'])\n",
    "output_svc_df.to_csv('./Output/svc_test_output.csv', sep=\",\", float_format='%d', index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZMEzwqFSkRQ"
   },
   "source": [
    "Output CSV file for Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "erYpOJNwNfYz"
   },
   "outputs": [],
   "source": [
    "output_rand_forest = opt_rand_forest.predict(data_test_feature)\n",
    "output_df_rand = pd.DataFrame(output_rand_forest, columns = ['label'])\n",
    "output_df_rand.to_csv('./Output/test_output.csv', sep=\",\", float_format='%d', index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3CW5s-TSvuu"
   },
   "source": [
    "Output CSV file for Logistic Regression Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAaeZbD75OLZ"
   },
   "outputs": [],
   "source": [
    "output_Logistic = opt_log.predict(data_test_feature)\n",
    "output_Logistic_df = pd.DataFrame(output_Logistic, columns = ['label'])\n",
    "output_Logistic_df.to_csv('./Output/test_output_log.csv', sep=\",\", float_format='%d', index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFiH_wQ7SwM5"
   },
   "source": [
    "Output CSV file for KNN Neighbor Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOuOIHjo5uIT"
   },
   "outputs": [],
   "source": [
    "output_knn = opt_nn.predict(data_test_feature)\n",
    "output_knn_df= pd.DataFrame(output_knn, columns = ['label'])\n",
    "output_knn_df.to_csv('./Output/knn_test_output.csv', sep=\",\", float_format='%d', index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13nz0GELSw74"
   },
   "source": [
    "Output CSV file for Decision Tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWZ6Osyv5-Lg"
   },
   "outputs": [],
   "source": [
    "output_decision_tree = opt_tree.predict(data_test_feature)\n",
    "output_decision_tree_df = pd.DataFrame(output_decision_tree, columns = ['label'])\n",
    "output_decision_tree_df.to_csv('./Output/de_tree_test_output.csv', sep=\",\", float_format='%d', index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naFiL_WZAJW3"
   },
   "source": [
    "### Output Prediction on Kaggle\n",
    "\n",
    "Accuracy: \n",
    "1. Random Forest Classifier: 77%\n",
    "2. Logistic Regression: 76.3%\n",
    "3. KNN: 69.8%\n",
    "4. Decision Tree: 57.8%\n",
    "5. Support Vector Machine: 9%\n",
    "\n",
    "Conclusion: Random forest classifier is our best model to predict the given test data set. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 1_2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}