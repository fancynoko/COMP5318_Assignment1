{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIcuB1qpXXzV"
      },
      "source": [
        "# COMP5318 - Machine Learning and Data Mining: Assignment 1\n",
        "<div style=\"text-align: right\"> Due: Friday Week 7 - Fri 8 April 2022 11:59PM </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbpresent": {
          "id": "375753da-1c6c-4b02-986a-6e3b185a5869"
        },
        "id": "-u7p4JTIXXza"
      },
      "source": [
        "# 1. Summary\n",
        "The goal of this assignment is to build a classifier to classify some grayscale images of the size 28x28 into a set of categories. The dimension of the original data is large, so you need to be smart on which method you gonna use and perhaps perform a pre-processing step to reduce the amount of computation. Part of your marks will be a function of the performance of your classifier on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlWbZY7JXXzc"
      },
      "source": [
        "# 2. Dataset description\n",
        "The dataset can be downloaded from Canvas. The dataset consists of a training set of 30,000 examples and a test set of 5,000 examples. They belong to 10 different categories. The validation set is not provided, but you can randomly pick a subset of the training set for validation. The features of the 5,000 test examples are given, you will analyse the performance of your proposed method by uploading the predicted labels of test examples onto [Kaggle Leaderboard](https://www.kaggle.com/t/a781604ffe46a42f903dd4be1b9daf16). You can find the instruction of using the leaderboard in Part 5.2. The leaderboard will compute the accuracy of your model, and team ranking will be shown based on the performance. Please note that we provide only PART of the original Fashion-MNIST, you must use the GIVEN `train.csv` (not the original dataset from the official website) for training; or it will be considered as cheating. <br />\n",
        "Here are examples illustrating samples of the dataset (each class takes one row):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRTiLolPXXzo"
      },
      "source": [
        "<img src=\"Dataset_image.jpg\" alt=\"DataSet\" title=\"DataSet\" width=\"450\" height=\"300\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBPRrkMpXXzo"
      },
      "source": [
        "There are 10 classes in total:\n",
        "\n",
        "    - 0 T-shirt/Top\n",
        "    - 1 Trouser\n",
        "    - 2 Pullover\n",
        "    - 3 Dress\n",
        "    - 4 Coat\n",
        "    - 5 Sandal\n",
        "    - 6 Shirt\n",
        "    - 7 Sneaker\n",
        "    - 8 Bag\n",
        "    - 9 Ankle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MSUFRO4XXzp"
      },
      "source": [
        "# 3. How to load the data and make output prediciton\n",
        "There is a Input folder including only 2 files (which can be downloaded from Canvas):\n",
        "\n",
        "    1. train.csv (30000 image samples for training including features and label) \n",
        "    2. test_input.csv (5000 images for prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwI46pc3XXzq"
      },
      "source": [
        "## 3.1 How to load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssDOH7_NXXzr"
      },
      "source": [
        "To read the *csv* file and load the data into a dataframe using pandas. \n",
        "\n",
        "The **training data files are in the ./Input/train** and **testing data file are in ./Input/test**. <br /> Use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3paNnx5YU_t",
        "outputId": "1b9eedaf-fbdd-4408-8d7d-0dd1db397ab7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "3Qzyym0PXXzt",
        "outputId": "310b57b7-1f71-4766-8490-bda49a00becd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b766712cd6f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/train'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "print(os.listdir(\"./data/train\"))\n",
        "pd.set_option('display.max_columns', 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SIz7li7zXXzv"
      },
      "outputs": [],
      "source": [
        "# train.csv including feature and label using for training model.\n",
        "data_train_df = pd.read_csv('/content/drive/MyDrive/COMP5318/data/train.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3IKpXj1XXzw"
      },
      "outputs": [],
      "source": [
        "data_train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-CkkeqQXXzx"
      },
      "source": [
        "Then data would be a dataframe with 30000 samples including 784 features (from v1 to v784) and its label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QZsQNQLUXXzx"
      },
      "outputs": [],
      "source": [
        "# Selecting input feature\n",
        "data_train_feature = data_train_df.loc[:, \"v1\":\"v784\"].to_numpy()\n",
        "\n",
        "# Selecting output lable \n",
        "data_train_label = data_train_df.label.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fDpn0DwXXzy"
      },
      "source": [
        "Showing a sample data. The first example belongs to class 2: Pullover"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcnqIBxnXXzz",
        "outputId": "d1b5a64d-32ac-48af-a9c6-97597b15278e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   1   0   0 131 184 199 229 234 217 212 204 208 226 227\n",
            "  203 185 173  44   0   4   0   0   0   0]\n",
            " [  0   0   0   0   2   0   0 214 224 116  78 149 141 148 131 121 141 141\n",
            "  169 212 251 136   0  10   0   0   0   0]\n",
            " [  0   0   1   0   5   0  43 220 217 213 104  13   6  49  36  11  37 121\n",
            "  179 208 227 155   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0 155 233 217 226 255 252 133  64 109 127 175 240\n",
            "  232 209 224 204   0   0   3   0   0   0]\n",
            " [  0   0   0   3   0   0 212 227 223 223 217 230 241 237 210 252 229 222\n",
            "  213 218 221 216   0   0   7   0   0   0]\n",
            " [  0   0   3   0  13 193 223 215 218 215 224 225 219 213 209 212 217 225\n",
            "  225 224 217 223 198   0   0   2   0   0]\n",
            " [  0   0   0   0 197 227 211 216 215 251 236 212 250 221 213 213 207 209\n",
            "  208 212 214 210 232 169   0   0   0   0]\n",
            " [  0   0   0  13 214 206 216 214 246 116  14  29   0 212 215 211 214 209\n",
            "  211 210 209 212 203 207   4   0   0   0]\n",
            " [  0   0   0  62 223 208 222 229 195   0 103   0   0 137 240 200 219 214\n",
            "  211 207 212 216 204 221  70   0   0   0]\n",
            " [  0   0   0 104 223 203 224 236 191  66  19  59  35  96 227 203 207 223\n",
            "  221 211 204 215 203 224 131   0   0   0]\n",
            " [  0   0   0 169 220 204 221 222 229  34   0  54   0 230 199 204 208 210\n",
            "  226 223 209 217 208 216 193   0   0   0]\n",
            " [  0   0   0 206 216 205 220 223 164 221 156 149 239 217 140 244 223 139\n",
            "  152 230 216 219 209 211 217   0   0   0]\n",
            " [  0   0   0 222 213 205 222 219 150 152 201 171 162 121 120 156 151 130\n",
            "  162 225 214 221 211 211 225   0   0   0]\n",
            " [  0   0   0 233 209 207 231 230 173 164 176 155 163 174 141 150 147 153\n",
            "  157 195 221 227 216 209 238   0   0   0]\n",
            " [  0   0  11 245 208 204 230 231 137 147 144 133 125 126 126 134 129 131\n",
            "  138 193 208 222 218 207 215  39   0   0]\n",
            " [  0   0  31 246 206 199 222 251 139  73  85  77  92 111 130 150 176 187\n",
            "  200 218 206 222 219 207 248  55   0   0]\n",
            " [  0   0  56 248 203 203 225 248 210 154 210 234 236 235 235 230 224 217\n",
            "  212 213 207 222 220 208 245  61   0   0]\n",
            " [  0   0  65 246 205 200 229 235 204 229 226 208 204 204 205 204 207 205\n",
            "  205 211 203 219 223 209 245  72   0   0]\n",
            " [  0   0  85 244 203 196 239 233 202 206 208 210 210 211 213 208 206 212\n",
            "  209 210 204 218 227 210 243  79   0   0]\n",
            " [  0   0 119 241 202 194 242 225 206 213 213 212 212 211 212 209 205 213\n",
            "  212 210 204 216 229 210 240 102   0   0]\n",
            " [  0   0 145 230 200 201 240 221 208 214 214 212 212 213 213 210 204 208\n",
            "  212 212 204 217 229 210 234 124   0   0]\n",
            " [  0   0 171 223 211 200 239 224 206 215 216 214 213 213 213 211 207 207\n",
            "  211 212 207 220 224 210 235 164   0   0]\n",
            " [  0   0 133 237 210 204 235 226 206 214 214 213 212 214 214 213 210 208\n",
            "  211 212 206 219 226 210 244 103   0   0]\n",
            " [  0   0  32 217 204 207 239 229 207 213 213 211 209 213 214 213 210 212\n",
            "  212 211 200 220 226 214 221  40   0   0]\n",
            " [  0   0  33 219 209 211 204 208 219 210 214 212 211 212 212 212 209 212\n",
            "  216 214 209 211 236 212 231  55   0   0]\n",
            " [  0   0  21 199 215 228 149 168 224 210 211 212 214 214 213 214 212 211\n",
            "  207 205 212  89 233 222 197  21   0   0]\n",
            " [  0   0   0   0  12  21   0 217 239 217 224 220 218 215 217 222 222 226\n",
            "  236 219 255  51   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  48 172 181 198 206 209 210 208 202 194 186\n",
            "  175 143 106   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "data_train_feature = data_train_feature.reshape((data_train_feature.shape[0], 28, 28))\n",
        "print(data_train_feature[0])\n",
        "plt.imshow(data_train_feature[0], cmap=plt.get_cmap('gray'))\n",
        "plt.title(\"class \" + str(data_train_label[0]) + \": Pullover\" )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ed7xb2KXXz0"
      },
      "source": [
        "## 3.2 How to loading test data and output the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HSRKvzIlXXz1"
      },
      "outputs": [],
      "source": [
        "# test_input.csv includes 5000 samples used for label prediction. Test samples do not have labels.\n",
        "data_test_df = pd.read_csv('/content/drive/MyDrive/COMP5318/data/test_input.csv', index_col=0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "-J5_EGSfXXz1",
        "outputId": "537e1b2a-fd1b-4287-9715-171917878761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    v1  v2  v3  v4  v5  v6  v7  v8  v9  v10  ...  v775  v776  v777  v778  \\\n",
              "id                                           ...                           \n",
              "0    0   0   0   0   0   0   0   0   0   10  ...    88     0     0     0   \n",
              "1    0   0   0   0   0   0   0   0  17  145  ...   124     0     0     0   \n",
              "2    0   0   0   0   0   0   0   0   0   69  ...    35     0     0     0   \n",
              "3    0   0   0   0   0   0   0   9  75  156  ...    74    53    19     0   \n",
              "4    0   0   0   0   0   0   0   1   1    0  ...     0     1     0     0   \n",
              "\n",
              "    v779  v780  v781  v782  v783  v784  \n",
              "id                                      \n",
              "0      0     0     0     0     0     0  \n",
              "1      0     0     0     0     0     0  \n",
              "2      0     0     0     0     0     0  \n",
              "3      1     0     0     0     0     0  \n",
              "4      0     0     0     0     0     0  \n",
              "\n",
              "[5 rows x 784 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20b25b6e-e4cf-4a96-82d0-ff0be6e68f8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v3</th>\n",
              "      <th>v4</th>\n",
              "      <th>v5</th>\n",
              "      <th>v6</th>\n",
              "      <th>v7</th>\n",
              "      <th>v8</th>\n",
              "      <th>v9</th>\n",
              "      <th>v10</th>\n",
              "      <th>...</th>\n",
              "      <th>v775</th>\n",
              "      <th>v776</th>\n",
              "      <th>v777</th>\n",
              "      <th>v778</th>\n",
              "      <th>v779</th>\n",
              "      <th>v780</th>\n",
              "      <th>v781</th>\n",
              "      <th>v782</th>\n",
              "      <th>v783</th>\n",
              "      <th>v784</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>145</td>\n",
              "      <td>...</td>\n",
              "      <td>124</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>69</td>\n",
              "      <td>...</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>75</td>\n",
              "      <td>156</td>\n",
              "      <td>...</td>\n",
              "      <td>74</td>\n",
              "      <td>53</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20b25b6e-e4cf-4a96-82d0-ff0be6e68f8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20b25b6e-e4cf-4a96-82d0-ff0be6e68f8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20b25b6e-e4cf-4a96-82d0-ff0be6e68f8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data_test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gvub8AfXXz1"
      },
      "source": [
        "After making a prediction on test data, all predicted lables will be saved in “test_output.csv”. You may use the following code to generate an output file that meets the requirement. The output file will be uploaded to both Kaggle and Canvas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EweuJrRgXXz2",
        "outputId": "b6c498b3-0acd-4aea-c196-22b1c0464503"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'output' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# assume output is the predicted labels from classifiers using input as data from test_input.csv\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# (5000,)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m output_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43moutput\u001b[49m, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m output_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Output/test_output.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, float_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m, index_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
          ]
        }
      ],
      "source": [
        "# assume output is the predicted labels from classifiers using input as data from test_input.csv\n",
        "# (5000,)\n",
        "\n",
        "output_df = pd.DataFrame(output, columns = ['label'])\n",
        "output_df.to_csv('./Output/test_output.csv', sep=\",\", float_format='%d', index_label=\"id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbpresent": {
          "id": "aca7ed33-2da5-4fbf-a861-8a886f4020a8"
        },
        "id": "EQkzEwkeXXz3"
      },
      "source": [
        "We will load the output file using the code for loading data above. It is your responsibility to make sure the output file can be correctly loaded using this code.\n",
        "The performance of your classifier will be evaluated in terms of the top-1 accuracy metric, i.e.<br /><br />\n",
        "<div style=\"text-align: center\"> $$\\text{Accuracy} = \\frac{\\text{Number of correct classifications}}{\\text{Total number of test examples used}} * 100\\%$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbpresent": {
          "id": "1e4a01db-cd92-48f8-bdaa-21c39456cfcb"
        },
        "id": "a6GspGVoXXz3"
      },
      "source": [
        "# 4. Task description\n",
        "\n",
        "Your task is to determine / build a classifier for the given data set to classify images into categories and write a report. The score allocation is as follows:\n",
        "\n",
        "    1. Code: max 65 points\n",
        "    2. Report: max 35 points\n",
        "    \n",
        "Please refer to the **rubric** in Canvas (Canvas -> Assignment1 -> Rubric) for detailed marking scheme. The report and the code are to be submitted in Canvas by the due date.<br />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NRCScxRXXz3"
      },
      "source": [
        "## 4.1 Code\n",
        "### The code must clearly show :\n",
        "    1. Pre-process data\n",
        "    2. Details of your implementation for each algorithm\n",
        "    3. Fine-tune hyper-parameters for each algorithm and running time\n",
        "    4. The comparison result between 4 different algorithms including 3 single methods and one ensemble method\n",
        "    5. Hardware and software specifications of the computer that you used for performance evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_Yz_KvTXXz4"
      },
      "source": [
        "### 4.1.1 Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu3WyiilXXz5"
      },
      "source": [
        "You will need to have at least one pre-process techique before you can apply the classification algorithms. Pre-process techique can be **Normalisation**, **PCA**, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data_train_feature, data_train_label , random_state=42\n",
        ")\n",
        "\n",
        "## Normalize the data\n",
        "s = MinMaxScaler()\n",
        "s.fit(X_train)\n",
        "Norm_data_train = s.transform(X_train)\n",
        "Norm_data_test = s.transform(X_test)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6xnrDPvAXXz5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z4dyOLOXXz5"
      },
      "source": [
        "### 4.1.2 Classification algorithms "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FezOflJbXXz6"
      },
      "source": [
        "You will now apply multiple classifiers to the pre-processed dataset. You have to implement at least 3 classifiers in particular:\n",
        "\n",
        "    1. Nearest Neighbor\n",
        "    2. Logistic Regression\n",
        "    3. Naïve Bayes \n",
        "    4. Decision Tree\n",
        "    5. SVM\n",
        "\n",
        "and one ensemble method:\n",
        "    \n",
        "    1. Bagging\n",
        "    2. Boosting\n",
        "    3. Random forest\n",
        "    \n",
        "For binary classifiers, we can use those classifiers for the data which has more than 2 labels using the one-vs-rest method. The implementation can use sklearn, or can be implemented from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Classifier accuracy on the test set: 0.84\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Classifier Methods\n",
        "#Neareast Neighbor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "nn = KNeighborsClassifier(n_neighbors=7)\n",
        "nn.fit(Norm_data_train, y_train)\n",
        "output_prediction = nn.predict(Norm_data_test)\n",
        "print(\"KNN Classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, output_prediction)))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3mmYOz2XXz6",
        "outputId": "438c25ec-f227-4042-c3e0-7de9599583a9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier accuracy on the test set: 0.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log_regression = LogisticRegression()\n",
        "log_regression.fit(Norm_data_train, y_train)\n",
        "l_predict = log_regression.predict(Norm_data_test)\n",
        "print(\"Logistic Regression Classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, l_predict)))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLM18AKoXXz7",
        "outputId": "b1dc28b1-9362-4565-8deb-e5b341fffb36"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Navie Bayes Classifier accuracy on the test set: 0.62\n"
          ]
        }
      ],
      "source": [
        "#Navie Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "GNB = GaussianNB()\n",
        "GNB.fit(Norm_data_train, y_train)\n",
        "G_predict = GNB.predict(Norm_data_test)\n",
        "print(\"Navie Bayes Classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, G_predict)))\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDkrHx5QXXz7",
        "outputId": "9ac293bf-d081-410b-d4e7-acc1d8c715d5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decsion tree classifier accuracy on the test set: 0.78\n"
          ]
        }
      ],
      "source": [
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tr = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"random\", random_state=42)\n",
        "tr.fit(Norm_data_train, y_train)\n",
        "t_predict = tr.predict(Norm_data_test)\n",
        "print(\"Decsion tree classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, t_predict)))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWs-RXWWXXz8",
        "outputId": "d65a84bc-04fb-4c27-a2ad-9ad945690dac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "D5gp9Lp3XXz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ensemble Method"
      ],
      "metadata": {
        "collapsed": false,
        "id": "FhSXIzKGXXz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#Bagging\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "tr_bg = BaggingClassifier(DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
        "                          max_samples=100, bootstrap=True, random_state=42)\n",
        "tr_bg.fit(Norm_data_train, y_train)\n",
        "bg_predict = tr_bg.predict(Norm_data_test)\n",
        "\n",
        "print(\"Bagging ensembles of decsion tree:{:.2f}\".format(accuracy_score(y_test, bg_predict)))\n",
        "\n",
        "#Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_tree = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
        "rf_tree.fit(Norm_data_train, y_train)\n",
        "rf_predict = rf_tree.predict(Norm_data_test)\n",
        "print(\"Random Forest ensembles of decsion tree:{:.2f}\".format(accuracy_score(y_test, rf_predict)))\n",
        "\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nfLz60xzXXz9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFNzX7OoXXz9"
      },
      "source": [
        "### 4.1.3 Parameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDwNKXJeXXz-"
      },
      "source": [
        "For each classifiers we would like to find the best parameters using grid search with k-fold (k>=5) cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Test set score: 0.85\n",
            "KNN Best parameters: {'n_neighbors': 5, 'p': 1}\n",
            "KNN Best cross-validation score: 0.85\n",
            "KNN Best estimator:\n",
            "KNeighborsClassifier(p=1)\n"
          ]
        }
      ],
      "source": [
        "# Tuning for KNeighbor Classifier\n",
        "KNN_para = {'n_neighbors': [1,3,5,11,15], 'p':[1,2]}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid_search_knn = GridSearchCV(nn, KNN_para, cv=5)\n",
        "grid_search_knn.fit(Norm_data_train, y_train)\n",
        "\n",
        "print(\"KNN Test set score: {:.2f}\".format(grid_search_knn.score(Norm_data_test, y_test)))\n",
        "print(\"KNN Best parameters: {}\".format(grid_search_knn.best_params_))\n",
        "print(\"KNN Best cross-validation score: {:.2f}\".format(grid_search_knn.best_score_))\n",
        "print(\"KNN Best estimator:\\n{}\".format(grid_search_knn.best_estimator_))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ_3HXGkXXz-",
        "outputId": "7f94a38c-bbce-4b66-b95c-2607dcbd00fd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression test set score: 0.84\n",
            "Logistic regression best parameters: {'max_iter': 2000}\n",
            "Logistic regression best cross-validation score: 0.84\n",
            "Logistic regression best estimator:\n",
            "LogisticRegression(max_iter=2000)\n"
          ]
        }
      ],
      "source": [
        "# Tuning for Logistic Regression classifier\n",
        "lr_para = {\n",
        "           'max_iter':[2000, 3000, 6000]}\n",
        "grid_search_lr = GridSearchCV(log_regression, lr_para, cv=5, return_train_score=10)\n",
        "grid_search_lr.fit(Norm_data_train, y_train)\n",
        "print(\"Logistic regression test set score: {:.2f}\".format(grid_search_lr.score(Norm_data_test, y_test)))\n",
        "print(\"Logistic regression best parameters: {}\".format(grid_search_lr.best_params_))\n",
        "print(\"Logistic regression best cross-validation score: {:.2f}\".format(grid_search_lr.best_score_))\n",
        "print(\"Logistic regression best estimator:\\n{}\".format(grid_search_lr.best_estimator_))\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP7j0J2LXXz_",
        "outputId": "7d17df69-b6ca-43ae-977c-35b4017620a0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Tuning for Naive Bayes\n",
        "# nb_para = {}\n",
        "# grid_search_nb = GridSearchCV(GNB, cv=5, return_train_score=10)\n",
        "# grid_search_nb.fit(Norm_data_train, y_train)\n",
        "\n",
        "# print(\"Logistic regression test set score: {:.2f}\".format(grid_search_nb.score(Norm_data_test, y_test)))\n",
        "# print(\"Logistic regression best parameters: {}\".format(grid_search_nb.best_params_))\n",
        "# print(\"Logistic regression best cross-validation score: {:.2f}\".format(grid_search_nb.best_score_))\n",
        "# print(\"Logistic regression best estimator:\\n{}\".format(grid_search_nb.best_estimator_))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "z67sJVTgXXz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree test set score: 0.78\n",
            "Decision Tree best parameters: {'min_samples_split': 30}\n",
            "Decision Tree best cross-validation score: 0.78\n",
            "Decision Tree best estimator:\n",
            "DecisionTreeClassifier(criterion='entropy', min_samples_split=30,\n",
            "                       random_state=42, splitter='random')\n"
          ]
        }
      ],
      "source": [
        "# Tuning for Decision Tree\n",
        "tree_para = {\"min_samples_split\": [10,20,30,40]}\n",
        "grid_search_dt = GridSearchCV(tr, tree_para, cv=5, return_train_score=True)\n",
        "grid_search_dt.fit(Norm_data_train, y_train)\n",
        "print(\"Decision Tree test set score: {:.2f}\".format(grid_search_dt.score(Norm_data_test, y_test)))\n",
        "print(\"Decision Tree best parameters: {}\".format(grid_search_dt.best_params_))\n",
        "print(\"Decision Tree best cross-validation score: {:.2f}\".format(grid_search_dt.best_score_))\n",
        "print(\"Decision Tree best estimator:\\n{}\".format(grid_search_dt.best_estimator_))\n",
        "\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-ftzQPRXX0A",
        "outputId": "0647654f-1e3d-404f-ee69-64802db97bf5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest test set score: 0.87\n",
            "Random Forest best parameters: {'criterion': 'entropy', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1}\n",
            "Random Forest best cross-validation score: 0.87\n",
            "Random Forest best estimator:\n",
            "RandomForestClassifier(criterion='entropy', min_samples_split=10, n_jobs=-1)\n"
          ]
        }
      ],
      "source": [
        "# Tuning for Ensemble method of RandomForest classifier \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest_para = {\"n_estimators\":[50, 100], \"criterion\":[\"gini\",\"entropy\"], \"min_samples_split\":[10,20,30,40],\n",
        "               \"n_jobs\": [-1]}\n",
        "grid_search_randf = GridSearchCV(RandomForestClassifier(), forest_para, return_train_score=True)\n",
        "grid_search_randf.fit(Norm_data_train, y_train)\n",
        "\n",
        "print(\"Random Forest test set score: {:.2f}\".format(grid_search_randf.score(Norm_data_test, y_test)))\n",
        "print(\"Random Forest best parameters: {}\".format(grid_search_randf.best_params_))\n",
        "print(\"Random Forest best cross-validation score: {:.2f}\".format(grid_search_randf.best_score_))\n",
        "print(\"Random Forest best estimator:\\n{}\".format(grid_search_randf.best_estimator_))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNagX1t_XX0A",
        "outputId": "cf5424db-d073-480d-c46b-ea691bcd6260"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDZj3xs6XX0A"
      },
      "source": [
        "### 4.1.4 Classifier comparisons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smuWn72rXX0A"
      },
      "source": [
        "After finding the best parameter for each algorithm, we would like to make comparisons between all classifiers using their own best hyper-parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Classifier accuracy on the test set: 0.85\n"
          ]
        }
      ],
      "source": [
        "# Optimized Classifier of KNN with the best hyper_parameters\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "opt_nn = KNeighborsClassifier(n_neighbors=5, p=1)\n",
        "opt_nn.fit(Norm_data_train, y_train)\n",
        "opt_output_prediction = opt_nn.predict(Norm_data_test)\n",
        "print(\"KNN Classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, opt_output_prediction)))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO07J7CKXX0B",
        "outputId": "5477f727-0413-4827-8562-bfcfbc82c773"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized Classifier of logistic regression with best hyperparameter \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "opt_log = LogisticRegression(max_iter=2000)\n",
        "opt_log.fit(Norm_data_train, y_train)\n",
        "opt_log_predict = opt_log.predict(Norm_data_test)\n",
        "print(\"Logistic Regression Classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, opt_log_predict)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-G-Kl8bR0IP",
        "outputId": "a0d4d96a-97df-4d1d-9251-c8375ae9adda"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier accuracy on the test set: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized Classifier of Decision Tree with the best hyper_parameter \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "opt_tree = DecisionTreeClassifier(criterion='entropy', min_samples_split=30,\n",
        "                       random_state=42, splitter='random')\n",
        "opt_tree.fit(Norm_data_train, y_train)\n",
        "opt_tree_predict = opt_tree.predict(Norm_data_test)\n",
        "print(\"Decision Tree Classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, opt_tree_predict)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNjFje4OR2aZ",
        "outputId": "2d1f3db5-eb7c-4ad4-c82a-d29ba239cc85"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier accuracy on the test set: 0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized Classifier of random forest with the best hyper_parameter \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "opt_rand_forest = RandomForestClassifier(n_estimators=100, criterion='entropy', min_samples_split=10, n_jobs=-1)\n",
        "opt_rand_forest.fit(Norm_data_train, y_train)\n",
        "opt_rand_forest_predict = opt_rand_forest.predict(Norm_data_test)\n",
        "print(\"Random forest classifier accuracy on the test set: {:.2f}\".format(accuracy_score(y_test, opt_rand_forest_predict)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz9dVVRkR2C4",
        "outputId": "f1e61a66-c8b8-4277-98e3-8e95c8d2b2ff"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random forest classifier accuracy on the test set: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mdlREjrXX0B"
      },
      "source": [
        "## 4.2 Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfbf_3E5XX0B"
      },
      "source": [
        "### The report must clearly show:\n",
        "    1. Details of your classifiers using for assignment 1\n",
        "    2. The predicted results from your classifier on test examples\n",
        "    3. Results comparison and discussion\n",
        "    4. Following the format in rubric : Introduction -> Methods -> Experiments result and discussion -> Conclusion\n",
        "    5. The maximum length of the report is 10 (excluding appendix and references)\n",
        "    6. Clearly provide instructions on how to run your code, hardware and software environments in the Appendix section of your report\n",
        "    7. Detail of student including ID, name\n",
        "    8. Please also refer rubric on Canvas for more detail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlj5GTYYXX0B"
      },
      "source": [
        "# 5. Instructions to hand in the assignment\n",
        "\n",
        "## 5.1 Submit to Canvas\n",
        "\n",
        "### Go to Canvas -> Assignments -> \"Assignment 1\" and submit 4 files: the report, the code files, and output file.\n",
        "\n",
        "   1. Report (a .pdf file).\n",
        "\n",
        "   2. Code (2 files include: a .ipynb file and a PDF file). PDF is exported from .ipynb file for plagiarism check. The code must be able to be run with the following folder structure:\n",
        "\n",
        "        - Notebook file (in the root folder): Your .ipynb file containing all Python code. The PDF file is generated from .ipynb file (File => Save as PDF file).\n",
        "    \n",
        "        - Input and Output folders: We will copy Input folder including all data and Output folder along with your notebook file to run your code. Please make sure your code is able to read the dataset from this Input folder and generate the output file to Output folder. (No need to submit the dataset and folder)\n",
        "\n",
        "   3. Output file (test_output.csv).\n",
        "\n",
        "If this is an individual work, an individual student still have to register the group on Canvas and submit all the files which must be named with student ID numbers following format e.g. **SIDxxxx_report.pdf**,  **SIDxxxx_code.ipynb**, **SIDxxxx_code.ipynb.pdf**.\n",
        "\n",
        "If this is a group work of 2, all students need to form a group on Canvas and one student submits all the files which must be named with student ID numbers of 2 members following format e.g. **SIDxxxx1_SIDxxxx2_report.pdf**,  **SIDxxxx1_SIDxxxx2_code.ipynb**, **SIDxxxx1_SIDxxxx2_code.ipynb.pdf**.\n",
        "\n",
        "\n",
        "## 5.2 Submit to Kaggle\n",
        "\n",
        "### Go to Kaggle ->  Join Competition -> Data (Download dataset) -> Submit Predictions\n",
        "We use the Kaggle leaderboard for assignment 1. Follow the steps below to use the leaderboard:\n",
        "\n",
        "   1. Use the [Kaggle link](https://www.kaggle.com/t/a781604ffe46a42f903dd4be1b9daf16) to join the competition, you need to create a Kaggle account if you don't have one.\n",
        "   \n",
        "   2. Go to Team -> Use your Canvas Group ID as your team name. You can create a Kaggle team with up to 2 members.\n",
        "\n",
        "   3. Go to Description -> Check the IMPORTANT NOTES for the assignment.\n",
        "    \n",
        "   4. Go to Data -> Download the training data, build your models.\n",
        "    \n",
        "   5. Submit Predictions -> Follow the submission format and submit your prediction output file (test_output.csv).\n",
        "\n",
        "   6. Leaderboard -> Check your accuracy score at the Leaderboard.\n",
        "\n",
        "**IMPORTANT**: This link is only available to the students of COMP5318. All groups need to submit test_output.csv to Kaggle for marking puporse. Only 5 submissions are allowed per day for Kaggle. Group ID on Canvas and Kaggle have to be unique otherwise the submission will not be marked for the Accuracy part.\n",
        "\n",
        "Kaggle link: https://www.kaggle.com/t/a781604ffe46a42f903dd4be1b9daf16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVzt-9PZXX0C"
      },
      "source": [
        "### A penalty of MINUS 5 percent (-5%) for each day after the due date. \n",
        "The maximum delay for assignment submission is 5 (five) days, after which assignment will not be accepted.\n",
        "\n",
        "**You should upload your assignment at least half a day or one day prior to the submission deadline to avoid network congestion**.\n",
        "\n",
        "Canvas may not be able to handle a large number of submission happening at the same time. If you submit your assignment at a time close to the deadline, a submission error may occur causing your submission to be considered late. Penalty will be applied to late submission regardless of issues. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZmu_jraXX0C"
      },
      "source": [
        "### All files required for assignment 1 can be downloaded from Canvas -> Assignments -> Assignment 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqqAhoCvXX0D"
      },
      "source": [
        "# 6. Inquiries after releasing the marking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cBAOEVxXX0D"
      },
      "source": [
        "**After Assignment 1 marks come out, please submit your inquiries about marking within the 1st week. All inquiries after that will be ignored.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN769F6AXX0D"
      },
      "source": [
        "# 7. Academic honesty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teG743iGXX0D"
      },
      "source": [
        "Please read the University policy on Academic Honesty very carefully: \n",
        "https://sydney.edu.au/students/academic-integrity.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br2Y6bhmXX0D"
      },
      "source": [
        "Plagiarism (copying from another student, website or other sources), making your work available to another student to copy, engaging another person to complete the assignments instead of you (for payment or not) are all examples of academic dishonesty. Note that when there is copying between students, both students are penalised – the student who copies and the student who makes his/her work available for copying. The University penalties are severe and include: \n",
        "\n",
        "    * a permanent record of academic dishonesty on your student file, \n",
        "    * mark deduction, ranging from 0 for the assignment to Fail for the course\n",
        "    * expulsion from the University and cancelling of your student visa. \n",
        "\n",
        "In addition, the Australian Government passed a new legislation last year (Prohibiting Academic Cheating Services Bill) that makes it a criminal offence to provide or advertise academic cheating services - the provision or undertaking of work for students which forms a substantial part of a student’s assessment task. Do not confuse legitimate co-operation and cheating!"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Assignment 1_2022.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}